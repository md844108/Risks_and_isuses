# Risks_and_isuses
## AIM : 
We have already seen how effective well-crafted prompts can be for various tasks using techniques like few-shot learning and chain-of-thought prompting. As we think about building real-world applications on top of LLMs, it becomes crucial to think about the misuses, risks, and safety practices involved with language models.
This section focuses on highlighting some of the risks and misuses of LLMs via techniques like prompt injections. It also highlights harmful behaviors and how to potentially mitigate them via effective prompting techniques.Â 
<br/>
Topics we covered: <br/>
 - Adversarial Prompting<br/>
 - Factuality<br/>
 - Biases<br/>

## References
  https://www.promptingguide.ai/risks

## Requirement OpenAI key
Open OpenAI website(https://platform.openai.com/account/api-keys) and create key , It will use in code.

## Install some pckages on which our dependency

        pip install openai
 
## To Run Code 
        Here, I'm using Jupyter Notebook to write code so you can run code to select cell from above to down.
